{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb639d3-e50a-4690-a0fb-86ce6cf769b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "--------------------------------------------------------------------------\n",
    "Measurement Error Analysis of Digital Toxicity and SEM with Extended Plots\n",
    "KODAQS Assignment: Indicators and Metrics of Data Quality\n",
    "--------------------------------------------------------------------------\n",
    "Author: Bastián González-Bustamante\n",
    "Email: b.a.gonzalez.bustamante@fgga.leidenuniv.nl\n",
    "Website: bgonzalezbustamante.com\n",
    "Date: 15 February 2025\n",
    "--------------------------------------------------------------------------\n",
    "Description:\n",
    "This script demonstrates a clean coding workflow for:\n",
    " 1. Loading and cleaning a Twitter/X toxicity dataset from Hugging Face:\n",
    "    https://huggingface.co/datasets/bgonzalezbustamante/toxicity-protests-ES\n",
    " 2. Computing inter-coder reliability (Cohen's Kappa) between two human \n",
    "    coders (coder_1 and coder_2).\n",
    " 3. Deriving a 'ground_truth' binary label from agreement between coder_1 \n",
    "    and coder_2.\n",
    " 4. Creating two binary toxicity indicators based on a continuous automated \n",
    "    measure obtained with Perspective API (distilled BERT model for toxicity):\n",
    "    - toxicity_60 = 1 if TOXICITY >= 0.6, else 0\n",
    "    - toxicity_70 = 1 if TOXICITY >= 0.7, else 0\n",
    " 5. Computing classification metrics (accuracy, precision, recall, F1-score)\n",
    "    for each thresholded variable (toxicity_60, toxicity_70), and generating\n",
    "    confusion matrix plots for each measure.\n",
    " 6. Plotting a boxplot of the distribution of TOXICITY (continuous variable) \n",
    "    by ground_truth.\n",
    " 7. Fitting a Structural Equation Model (SEM) with 'true_toxic' as a latent \n",
    "    variable indicated by:\n",
    "    - coder_1 (binary)\n",
    "    - coder_2 (binary)\n",
    "    - toxicity_60 (binary)\n",
    "    - toxicity_70 (binary)\n",
    " 8. Saving a Markdown report (measurement_error_KODAQS_Gonzalez-Bustamante.md)\n",
    "    containing:\n",
    "    - Inter-coder reliability (Cohen's Kappa)\n",
    "    - Classification metrics (accuracy, precision, recall, F1-score)\n",
    "    - Confusion matrices and distribution plots embedded as images\n",
    "    - SEM factor loadings (rounded to three decimals)\n",
    "    - Optionally an embedded path diagram (requires Graphviz installed)\n",
    "    - Some takeaways and limitations\n",
    "    - Python library version information\n",
    "--------------------------------------------------------------------------\n",
    "Usage:\n",
    "    python measurement_error_KODAQS_Gonzalez-Bustamante.py\n",
    "--------------------------------------------------------------------------\n",
    "Python and library versions:\n",
    "    Python v3.11.5\n",
    "    pandas v2.2.3\n",
    "    numpy v2.1.3\n",
    "    seaborn v0.13.2\n",
    "    scikit-learn v1.5.2\n",
    "    semopy v2.3.11\n",
    "    graphviz v0.20.3\n",
    "--------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "##########################################################################\n",
    "## 1. Import libraries (with versions)\n",
    "##########################################################################\n",
    "\n",
    "## General dependencies\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## scikit-learn metrics\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    cohen_kappa_score,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "## semopy for SEM\n",
    "from semopy import Model, semplot\n",
    "from graphviz import ExecutableNotFound\n",
    "\n",
    "## Function for library version in Markdown report\n",
    "def print_library_versions() -> str:\n",
    "    \"\"\"\n",
    "    Return a markdown-formatted string with Python library versions\n",
    "    for reproducibility and transparency.\n",
    "    \"\"\"\n",
    "    import sklearn\n",
    "    import semopy\n",
    "    import graphviz\n",
    "\n",
    "    text = (\n",
    "        f\"**Python version**: {sys.version.split(' ')[0]}\\n\\n\"\n",
    "        f\"**pandas version**: {pd.__version__}\\n\\n\"\n",
    "        f\"**numpy version**: {np.__version__}\\n\\n\"\n",
    "        f\"**seaborn version**: {sns.__version__}\\n\\n\"\n",
    "        f\"**scikit-learn version**: {sklearn.__version__}\\n\\n\"\n",
    "        f\"**semopy version**: {semopy.__version__}\\n\\n\"\n",
    "        f\"**graphviz version**: {graphviz.__version__}\\n\\n\"\n",
    "    )\n",
    "    return text\n",
    "\n",
    "##########################################################################\n",
    "## 2. Data and plotting functions \n",
    "##########################################################################\n",
    "\n",
    "def load_data(filepath: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load a CSV file into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath : str\n",
    "        URL to the CSV file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean the dataset by:\n",
    "      - Dropping duplicates based on 'id_obs'.\n",
    "      - Dropping rows missing coder_1, coder_2, or TOXICITY.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Cleaned dataset.\n",
    "    \"\"\"\n",
    "    df.drop_duplicates(subset=\"id_obs\", inplace=True)\n",
    "    df.dropna(subset=[\"coder_1\", \"coder_2\", \"TOXICITY\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def save_confusion_matrix_plot(\n",
    "    df: pd.DataFrame,\n",
    "    predicted_col: str,\n",
    "    truth_col: str,\n",
    "    filename: str\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Generate and save a confusion matrix plot as a PNG file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Data containing binary columns for prediction and ground-truth.\n",
    "    predicted_col : str\n",
    "        Column name for the predicted toxicity (0 or 1).\n",
    "    truth_col : str\n",
    "        Column name for the ground-truth (0 or 1).\n",
    "    filename : str\n",
    "        Output file name to save the plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(df[truth_col], df[predicted_col])\n",
    "    plt.figure(figsize=(4.5, 4))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "        yticklabels=[\"True 0\", \"True 1\"]\n",
    "    )\n",
    "    plt.title(f\"Confusion Matrix: {predicted_col}\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def save_toxicity_distribution_plot(df: pd.DataFrame, filename: str) -> None:\n",
    "    \"\"\"\n",
    "    Save a boxplot of the distribution of TOXICITY by ground_truth label.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing 'TOXICITY' and 'ground_truth'.\n",
    "    filename : str\n",
    "        File name to save the plot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=\"ground_truth\", y=\"TOXICITY\", data=df)\n",
    "    plt.title(\"Distribution of TOXICITY by Ground-Truth\")\n",
    "    plt.xlabel(\"Ground Truth (0 = Non-Toxic, 1 = Toxic)\")\n",
    "    plt.ylabel(\"TOXICITY Perspective API Score\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "##########################################################################\n",
    "## 3. Metrics and labels\n",
    "##########################################################################\n",
    "\n",
    "def compute_inter_rater_reliability(df: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Compute Cohen's Kappa for coder_1 and coder_2.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain 'coder_1' and 'coder_2' columns.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Cohen's Kappa score.\n",
    "    \"\"\"\n",
    "    return cohen_kappa_score(df[\"coder_1\"], df[\"coder_2\"])\n",
    "\n",
    "def derive_ground_truth(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create 'ground_truth' by labeling a tweet toxic if\n",
    "    coder_1 == 1 OR coder_2 == 1.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with a new 'ground_truth' column (0 or 1).\n",
    "    \"\"\"\n",
    "    df[\"ground_truth\"] = ((df[\"coder_1\"] == 1) | (df[\"coder_2\"] == 1)).astype(int)\n",
    "    return df\n",
    "\n",
    "def create_binary_toxicity_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create binary columns for thresholds 0.6 and 0.7 on TOXICITY:\n",
    "    - toxicity_60 = 1 if TOXICITY >= 0.6, else 0\n",
    "    - toxicity_70 = 1 if TOXICITY >= 0.7, else 0\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Updated DataFrame with 'toxicity_60' and 'toxicity_70'.\n",
    "    \"\"\"\n",
    "    df[\"toxicity_60\"] = (df[\"TOXICITY\"] >= 0.6).astype(int)\n",
    "    df[\"toxicity_70\"] = (df[\"TOXICITY\"] >= 0.7).astype(int)\n",
    "    return df\n",
    "\n",
    "def compute_classification_metrics(\n",
    "    df: pd.DataFrame,\n",
    "    pred_col: str,\n",
    "    truth_col: str = \"ground_truth\"\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute classification metrics: accuracy, precision, recall and F1-score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    pred_col : str\n",
    "        Name of the binary predicted column (0 or 1).\n",
    "    truth_col : str, optional\n",
    "        Name of the ground-truth column, by default 'ground_truth'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary with 'accuracy', 'precision', 'recall', 'f1_score' for the \n",
    "        given columns.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(df[truth_col], df[pred_col])\n",
    "    prec = precision_score(df[truth_col], df[pred_col], zero_division=0)\n",
    "    rec = recall_score(df[truth_col], df[pred_col], zero_division=0)\n",
    "    f1 = f1_score(df[truth_col], df[pred_col], zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": round(acc, 3),\n",
    "        \"precision\": round(prec, 3),\n",
    "        \"recall\": round(rec, 3),\n",
    "        \"f1_score\": round(f1, 3)\n",
    "    }\n",
    "\n",
    "##########################################################################\n",
    "## 4. SEM\n",
    "##########################################################################\n",
    "\n",
    "def fit_sem_model(df: pd.DataFrame) -> Model:\n",
    "    \"\"\"\n",
    "    Fit a Structural Equation Model (SEM) for latent variable 'true_toxic'\n",
    "    indicated by coder_1, coder_2, toxicity_60 and toxicity_70.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing coder_1, coder_2, toxicity_60, toxicity_70.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    semopy.Model\n",
    "        Fitted SEM model object.\n",
    "    \"\"\"\n",
    "    model_spec = \"\"\"\n",
    "    true_toxic =~ coder_1 + coder_2 + toxicity_60 + toxicity_70\n",
    "    \"\"\"\n",
    "    sem_model = Model(model_spec)\n",
    "    sem_model.fit(df)\n",
    "    return sem_model\n",
    "\n",
    "def format_sem_table(\n",
    "    df: pd.DataFrame,\n",
    "    columns_to_format=None,\n",
    "    decimals: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert numeric values in specific columns to a formatted string\n",
    "    with the given number of decimals, ignoring non-numeric placeholders\n",
    "    like '-' or empty strings.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame returned by sem_model.inspect(...)\n",
    "    columns_to_format : list of str, optional\n",
    "        Column names to format (e.g., ['Est.', 'Std.Err', 'z-value', 'p-value']).\n",
    "        If None, defaults to these four.\n",
    "    decimals : int, optional\n",
    "        Number of decimal places to format, by default 3\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A copy of df with selected columns formatted as strings where possible.\n",
    "    \"\"\"\n",
    "    import math\n",
    "\n",
    "    if columns_to_format is None:\n",
    "        columns_to_format = [\"Estimate\", \"Est. Std\", \"Std. Err\", \"z-value\", \"p-value\"]\n",
    "\n",
    "    ## Work on a copy so we don't overwrite the original DataFrame\n",
    "    df_formatted = df.copy()\n",
    "\n",
    "    ## Helper function: attempt float conversion, otherwise return original\n",
    "    def format_value(x):\n",
    "        ## If x is null or a dash-like placeholder, return empty\n",
    "        if pd.isnull(x) or x == '-':\n",
    "            return \"\"\n",
    "        try:\n",
    "            ## Convert to float and format\n",
    "            val = float(x)\n",
    "            return f\"{val:.{decimals}f}\"\n",
    "        except (ValueError, TypeError):\n",
    "            ## If conversion fails, leave as-is\n",
    "            return str(x)\n",
    "\n",
    "    for col in columns_to_format:\n",
    "        if col in df_formatted.columns:\n",
    "            df_formatted[col] = df_formatted[col].apply(format_value)\n",
    "\n",
    "    return df_formatted\n",
    "\n",
    "##########################################################################\n",
    "## 5. Main execution flow\n",
    "##########################################################################\n",
    "\n",
    "def main() -> None:\n",
    "    \"\"\"\n",
    "    Main orchestration function that:\n",
    "     1. Loads and cleans data.\n",
    "     2. Computes Cohen's Kappa.\n",
    "     3. Derives ground_truth variable.\n",
    "     4. Creates binary toxicity columns (toxicity_60, toxicity_70).\n",
    "     5. Computes classification metrics for each threshold and saves confusion \n",
    "        matrix plots.\n",
    "     6. Plots distribution of TOXICITY Perspective API score by ground_truth.\n",
    "     7. Fits an SEM and prints results (rounded to three decimals for all columns).\n",
    "     8. Saves a final Markdown report including:\n",
    "        - Cohen's Kappa\n",
    "        - Classification metrics for toxicity_60 and toxicity_70\n",
    "        - Confusion matrix plots, distribution plot\n",
    "        - SEM factor loadings\n",
    "        - (Optional) embedded path diagram if Graphviz is installed\n",
    "        - Python library version info\n",
    "    \"\"\"\n",
    "    ## 1. Load and clean\n",
    "    filepath = \"hf://datasets/bgonzalezbustamante/toxicity-protests-ES/goldstd_protests.csv\"\n",
    "    df_raw = load_data(filepath)\n",
    "    df_clean = clean_data(df_raw)\n",
    "\n",
    "    ## 2. Inter-rater reliability\n",
    "    kappa = compute_inter_rater_reliability(df_clean)\n",
    "\n",
    "    ## 3. Ground truth\n",
    "    df_clean = derive_ground_truth(df_clean)\n",
    "\n",
    "    ## 4. Binary indicators for TOXICITY\n",
    "    df_clean = create_binary_toxicity_columns(df_clean)\n",
    "\n",
    "    ## 5. Classification metrics and confusion matrices\n",
    "    metrics_tox_60 = compute_classification_metrics(df_clean, \"toxicity_60\", \"ground_truth\")\n",
    "    metrics_tox_70 = compute_classification_metrics(df_clean, \"toxicity_70\", \"ground_truth\")\n",
    "\n",
    "    ## Save confusion matrix plots\n",
    "    save_confusion_matrix_plot(df_clean, \"toxicity_60\", \"ground_truth\", \"cm_tox_60.png\")\n",
    "    save_confusion_matrix_plot(df_clean, \"toxicity_70\", \"ground_truth\", \"cm_tox_70.png\")\n",
    "\n",
    "    ## 6. Distribution of TOXICITY by ground_truth\n",
    "    save_toxicity_distribution_plot(df_clean, \"toxicity_distribution.png\")\n",
    "\n",
    "    ## 7. Fit SEM\n",
    "    sem_model = fit_sem_model(df_clean)\n",
    "    unstd_raw = sem_model.inspect(std_est=False)\n",
    "    std_raw   = sem_model.inspect(std_est=True)\n",
    "    \n",
    "    ## Format specific columns to 3 decimals\n",
    "    unstd_fmt = format_sem_table(unstd_raw, decimals=3)\n",
    "    std_fmt   = format_sem_table(std_raw, decimals=3)\n",
    "\n",
    "    ## Attempt to generate a path diagram\n",
    "    diagram_generated = False\n",
    "    try:\n",
    "        semplot(sem_model, show=False, plot_covs=True, filename=\"sem_path.png\")\n",
    "        diagram_generated = True\n",
    "    except ExecutableNotFound:\n",
    "        pass\n",
    "\n",
    "    ## 8. Build Markdown report\n",
    "    report_text = []\n",
    "    report_text.append(\"# Measurement Error Analysis of Digital Toxicity and SEM with Extended Plots\\n\")\n",
    "    report_text.append(\"## KODAQS Assignment: Indicators and Metrics of Data Quality\\n\")\n",
    "    report_text.append(\"**Bastián González-Bustamante**\\nb.a.gonzalez.bustamante@fgga.leidenuniv.nl\\n\")\n",
    "\n",
    "    ## Overview\n",
    "    report_text.append(\"## 1. Overview\\n\")\n",
    "    report_text.append(\n",
    "        \"In the previous 'Data Quality Pre-Registration', I reviewed the methodological \"\n",
    "        \"execution regarding data quality of the paper 'A Gladiatorial Arena: Incivility \"\n",
    "        \"in the Canadian House of Commons,' recently published in the *Journal of Politics*. \"\n",
    "        \"This paper focused on the prevalence and evolution of uncivil behaviour in the \"\n",
    "        \"Canadian House of Commons. Using machine learning techniques, the authors \"\n",
    "        \"analysed a dataset of parliamentary interventions.\\n\"\n",
    "    )\n",
    "    report_text.append(\n",
    "        \"This paper relies on Perspective API to measure incivility using emotional \"\n",
    "        \"attributes such as identity attack, insult, profanity, threat and toxicity. \"\n",
    "        \"Perspective API is a distilled BERT trained by Jigsaw and Google on millions \"\n",
    "        \"of comments from Wikipedia, media and information labelled by crowdsource \"\n",
    "        \"raters. Some intrinsic data quality problems were detected associated with \"\n",
    "        \"Perspective API's limitations because it was trained for online discussions \"\n",
    "        \"rather than parliamentary debates. In addition, the work's absence of \"\n",
    "        \"ground-truth evaluations or human-in-the-loop annotations also denoted \"\n",
    "        \"a problematic lack of external evidence.\\n\"\n",
    "    )\n",
    "    report_text.append(\n",
    "        \"In this script/report, I focused on a dataset developed on my own in the \"\n",
    "        \"framework of a project funded by the OpenAI Academic Programme 2024 to \"\n",
    "        \"benchmark Large Language Models’ annotation capabilities \"\n",
    "        \"(GitHub repository: https://github.com/training-datalab/gold-standard-toxicity). \"\n",
    "        \"We labelled a sample of a novel dataset of political interactions on Twitter \"\n",
    "        \"(rebranded as X) to generate ground-truth labels with human coders. Our sample \"\n",
    "        \"is balanced considering the probability score of Perspective API, which was \"\n",
    "        \"applied to the entire dataset and serves as a baseline. The dataset offers \"\n",
    "        \"two annotations per observation, therefore, I am able to compare the Perspective \"\n",
    "        \"API score with a human gold standard and conduct a measurement error analysis.\\n\"\n",
    "    )\n",
    "    report_text.append(\n",
    "        \"This is relevant because there are a number of concerns about the validity and \"\n",
    "        \"reliability of measures such as Perspective API or other BERT and LLMs \"\n",
    "        \"classification outputs. For example, Perspective API's score is a probability \"\n",
    "        \"score, and the technical documentation of the model suggests carefully \"\n",
    "        \"considering a threshold of 0.70 or even higher for the final classification. \"\n",
    "        \"Surprisingly, some comparisons with human annotations have suggested that a \"\n",
    "        \"lower threshold could be closer to human judgements. In this vein, a measurement \"\n",
    "        \"error of these automated indicators is relevant.\\n\"\n",
    "    )\n",
    "\n",
    "    ## Inter-coder reliability\n",
    "    report_text.append(\"## 1. Inter-coder reliability\\n\")\n",
    "    report_text.append(f\"**Cohen's Kappa = {kappa:.3f}** (between coder_1 and coder_2)\\n\")\n",
    "    report_text.append(\n",
    "        \"**Main takeaway:** The inter-coder reliability was excellent. The entire \"\n",
    "        \"process involved 7.2 hours of annotation and 1.2 hours of revision on the \"\n",
    "        \"online platform Labelbox.\\n\"\n",
    "    )\n",
    "\n",
    "    ## Classification metrics\n",
    "    report_text.append(\"## 2. Classification metrics\\n\")\n",
    "    report_text.append(\n",
    "        \"The performance metrics are: (i) accuracy that reports the proportion of \"\n",
    "        \"correct predictions of the particular classifier in comparison with the \"\n",
    "        \"human gold standard; (ii) precision that shows the ability of the \"\n",
    "        \"classifier to identify positive predicted values to identify false negatives; \"\n",
    "        \"(iii) recall or sensitivity that shows the proportion of correct classifications \"\n",
    "        \"among true-positive cases; and (iv) F1-score, a combination of precision \"\n",
    "        \"and recall.\\n\"\n",
    "    )\n",
    "    \n",
    "    report_text.append(\"**Perspective API threshold = 0.6**\\n\")\n",
    "    report_text.append(f\"- Accuracy: {metrics_tox_60['accuracy']}\\n\")\n",
    "    report_text.append(f\"- Precision: {metrics_tox_60['precision']}\\n\")\n",
    "    report_text.append(f\"- Recall: {metrics_tox_60['recall']}\\n\")\n",
    "    report_text.append(f\"- F1-score: {metrics_tox_60['f1_score']}\\n\\n\")\n",
    "\n",
    "    report_text.append(\"**Perspective API threshold = 0.7**\\n\")\n",
    "    report_text.append(f\"- Accuracy: {metrics_tox_70['accuracy']}\\n\")\n",
    "    report_text.append(f\"- Precision: {metrics_tox_70['precision']}\\n\")\n",
    "    report_text.append(f\"- Recall: {metrics_tox_70['recall']}\\n\")\n",
    "    report_text.append(f\"- F1-score: {metrics_tox_70['f1_score']}\\n\\n\")\n",
    "\n",
    "    ## Confusion matrix images\n",
    "    report_text.append(\"### Confusion Matrices\\n\")\n",
    "    report_text.append(\"![Confusion Matrix (tox_60)](cm_tox_60.png)\\n\\n\")\n",
    "    report_text.append(\"![Confusion Matrix (tox_70)](cm_tox_70.png)\\n\\n\")\n",
    "\n",
    "    ## Distribution plot\n",
    "    report_text.append(\"### Distribution of Perspective API Score by Ground-Truth\\n\")\n",
    "    report_text.append(\"![TOXICITY Distribution](toxicity_distribution.png)\\n\\n\")\n",
    "\n",
    "    ## Interpretation\n",
    "    report_text.append(\n",
    "        \"**Main takeaway:** Perspective API with a laxer cut-off threshold at 0.60 is closer \"\n",
    "        \"to our ground-truth measure elaborated with human coders.\\n\"\n",
    "    )\n",
    "    \n",
    "    ## SEM Explanation\n",
    "    report_text.append(\"## 3. SEM Results\\n\")\n",
    "    report_text.append(\n",
    "        \"The Structural Equation Model (SEM) treats 'true_toxic' as a latent factor \"\n",
    "        \"indicated by both human-coded labels (coder_1, coder_2) and threshold-based \"\n",
    "        \"binary measures (toxicity_60, toxicity_70). This allows me to integrate multiple \"\n",
    "        \"sources of measurement, potentially reducing errors associated with any single \"\n",
    "        \"indicator.\\n\"\n",
    "    )\n",
    "    report_text.append(\n",
    "        \"By examining factor loadings for each indicator, I can identify which measures \"\n",
    "        \"are most strongly associated with the latent toxicity construct. Higher loadings \"\n",
    "        \"imply a more reliable indicator. Moreover, the SEM framework accounts for \"\n",
    "        \"measurement error explicitly, providing a more robust estimate of true toxicity.\\n\"\n",
    "    )\n",
    "\n",
    "    ## If diagram was generated, embed in Markdown\n",
    "    if diagram_generated:\n",
    "        report_text.append(\"### Path Diagram\\n\\n\")\n",
    "        report_text.append(\"![SEM Diagram](sem_path.png)\\n\\n\")\n",
    "\n",
    "    ## Build the Markdown report\n",
    "    report_text.append(\"### SEM Factor Loadings (Unstandardised)\\n\\n\")\n",
    "    report_text.append(unstd_fmt.to_markdown(index=False))\n",
    "    report_text.append(\"\\n\\n### SEM Factor Loadings (Standardised)\\n\\n\")\n",
    "    report_text.append(std_fmt.to_markdown(index=False))\n",
    "    report_text.append(\"\\n\")\n",
    "    report_text.append(\n",
    "        \"**Main takeaways:** The standardised loadings show that coder_1 and coder_2 have strong \"\n",
    "        \"relationships with the underlying latent factor (0.969 and 0.972). This indicates that \"\n",
    "        \"the human-coded labels provide the clearest signals of 'true toxicity.' The \"\n",
    "        \"threshold-based measures (toxicity_60 and toxicity_70) also significantly reflect the \"\n",
    "        \"latent construct but with somewhat lower loadings (0.786 and 0.641), suggesting that \"\n",
    "        \"while they do capture some aspects of toxicity, they contribute less variance to the \"\n",
    "        \"latent factor than human coders, especially Perspective API with a threshold of 0.70, \"\n",
    "        \"which aligns with the classification metrics above.\\n\"\n",
    "    )\n",
    "    report_text.append(\n",
    "        \"**Limitations:** Binary indicators were used for both the human-coded variables and the \"\n",
    "        \"Perspective API thresholds. Binary indicators may oversimplify the underlying continuum \"\n",
    "        \"of toxicity. In addition, classical SEM with maximum-likelihood estimation may not be \"\n",
    "        \"strictly optimal for categorical data, sometimes warranting robust estimators or \"\n",
    "        \"specialised approaches (e.g., WLSMV or IRT models). Therefore, these factor loadings \"\n",
    "        \"are informative but may slightly misrepresent the nuanced gradations of toxicity.\\n\"\n",
    "    )\n",
    "\n",
    "    ## Library Versions\n",
    "    report_text.append(\"## 4. Library versions\\n\\n\")\n",
    "    report_text.append(print_library_versions())\n",
    "\n",
    "    final_markdown = \"\\n\".join(report_text)\n",
    "\n",
    "    ## Save the final Markdown to a file\n",
    "    with open(\"measurement_error_KODAQS_Gonzalez-Bustamante.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_markdown)\n",
    "\n",
    "    print(\"Markdown report saved as 'measurement_error_KODAQS_Gonzalez-Bustamante.md'.\")\n",
    "    print(\"Confusion matrix plots and TOXICITY distribution plot have been saved.\")\n",
    "    if diagram_generated:\n",
    "        print(\"SEM diagram saved as 'sem_path.png'.\")\n",
    "    else:\n",
    "        print(\"Diagram not generated (Graphviz not installed or not on PATH).\")\n",
    "\n",
    "##########################################################################\n",
    "## Script entry point\n",
    "##########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d77e1c-6bae-41d9-81cf-b07252c5cb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
